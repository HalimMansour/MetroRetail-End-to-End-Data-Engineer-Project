  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2026-01-07T10:26:25.226+0200] {_client.py:1025} INFO - HTTP Request: GET https://apacheairflow.gateway.scarf.sh/scheduler?version=2.10.2&python_version=3.12&platform=Linux&arch=x86_64&database=sqlite&db_version=3.45&executor=SequentialExecutor "HTTP/1.1 200 OK"
[2026-01-07T10:27:02.151+0200] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2026-01-07T10:27:03.113+0200] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2026-01-07T10:27:03.121+0200] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2026-01-07T10:27:03.167+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 10872
[2026-01-07T10:27:03.178+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07 10:27:03 +0200] [10870] [INFO] Starting gunicorn 23.0.0
[2026-01-07 10:27:03 +0200] [10870] [ERROR] Connection in use: ('::', 8793)
[2026-01-07 10:27:03 +0200] [10870] [ERROR] connection to ('::', 8793) failed: [Errno 98] Address already in use
[2026-01-07T10:27:03.285+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T10:27:03.311+0200] {scheduler_job_runner.py:1870} INFO - Marked 1 SchedulerJob instances as failed
[2026-01-07 10:27:04 +0200] [10870] [ERROR] Connection in use: ('::', 8793)
[2026-01-07 10:27:04 +0200] [10870] [ERROR] connection to ('::', 8793) failed: [Errno 98] Address already in use
[2026-01-07T10:27:04.388+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07 10:27:05 +0200] [10870] [ERROR] Connection in use: ('::', 8793)
[2026-01-07 10:27:05 +0200] [10870] [ERROR] connection to ('::', 8793) failed: [Errno 98] Address already in use
[2026-01-07 10:27:06 +0200] [10870] [ERROR] Connection in use: ('::', 8793)
[2026-01-07 10:27:06 +0200] [10870] [ERROR] connection to ('::', 8793) failed: [Errno 98] Address already in use
[2026-01-07 10:27:07 +0200] [10870] [ERROR] Connection in use: ('::', 8793)
[2026-01-07 10:27:07 +0200] [10870] [ERROR] connection to ('::', 8793) failed: [Errno 98] Address already in use
[2026-01-07 10:27:08 +0200] [10870] [ERROR] Can't connect to ('::', 8793)
[2026-01-07T10:27:13.793+0200] {job.py:229} INFO - Heartbeat recovered after 47.81 seconds
[2026-01-07T10:27:50.681+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T10:29:07.934+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T10:30:39.682+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T10:30:44.863+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
Dag run  in running state
Dag information Queued at: 2026-01-07 08:32:12.399114+00:00 hash info: 189fbf44625e032fc419f2fbf1f07576
[2026-01-07T10:32:15.733+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T10:32:47.316+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T10:34:20.870+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: metro_retail_pipeline.ingest_csv_files manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>
[2026-01-07T10:34:20.882+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 1/16 running and queued tasks
[2026-01-07T10:34:20.886+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: metro_retail_pipeline.ingest_csv_files manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>
[2026-01-07T10:34:20.915+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: metro_retail_pipeline.ingest_csv_files manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-01-07T10:34:20.926+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='ingest_csv_files', run_id='manual__2026-01-07T08:32:07.281049+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2026-01-07T10:34:20.930+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'ingest_csv_files', 'manual__2026-01-07T08:32:07.281049+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:34:20.954+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'ingest_csv_files', 'manual__2026-01-07T08:32:07.281049+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:35:38.757+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T10:35:48.556+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:35:48.961+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T10:35:48.972+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:35:50.227+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:35:50.506+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:35:53.108+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T10:35:53.918+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.ingest_csv_files manual__2026-01-07T08:32:07.281049+00:00 [queued]> on host Halim-NVG.localdomain
[2026-01-07T10:36:09.776+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='ingest_csv_files', run_id='manual__2026-01-07T08:32:07.281049+00:00', try_number=1, map_index=-1)
[2026-01-07T10:36:10.562+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=ingest_csv_files, run_id=manual__2026-01-07T08:32:07.281049+00:00, map_index=-1, run_start_date=2026-01-07 08:35:55.219459+00:00, run_end_date=2026-01-07 08:36:06.503305+00:00, run_duration=11.283846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=2, job_id=34, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2026-01-07 08:35:35.132359+00:00, queued_by_job_id=23, pid=11630
[2026-01-07T10:36:10.690+0200] {manager.py:293} ERROR - DagFileProcessorManager (PID=10872) last sent a heartbeat 108.49 seconds ago! Restarting it
[2026-01-07T10:36:10.745+0200] {process_utils.py:132} INFO - Sending 15 to group 10872. PIDs of all processes in the group: [10872]
[2026-01-07T10:36:10.749+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 10872
[2026-01-07T10:36:53.572+0200] {process_utils.py:80} INFO - Process psutil.Process(pid=10872, status='terminated', exitcode=0) (10872) terminated with exit code 0
[2026-01-07T10:36:53.678+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 11681
[2026-01-07T10:36:53.977+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T10:36:55.234+0200] {job.py:229} INFO - Heartbeat recovered after 156.31 seconds
[2026-01-07T10:36:55.946+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T10:37:04.694+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>
	<TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:32:11.141448+00:00 [scheduled]>
[2026-01-07T10:37:04.698+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 0/16 running and queued tasks
[2026-01-07T10:37:04.701+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 1/16 running and queued tasks
[2026-01-07T10:37:04.704+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>
	<TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:32:11.141448+00:00 [scheduled]>
[2026-01-07T10:37:04.736+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>, <TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:32:11.141448+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-01-07T10:37:04.740+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_staging', run_id='manual__2026-01-07T08:32:07.281049+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2026-01-07T10:37:04.743+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_staging', 'manual__2026-01-07T08:32:07.281049+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:37:04.746+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_staging', run_id='manual__2026-01-07T08:32:11.141448+00:00', try_number=3, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2026-01-07T10:37:04.750+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_staging', 'manual__2026-01-07T08:32:11.141448+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:37:04.810+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_staging', 'manual__2026-01-07T08:32:07.281049+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
OSError while attempting to symlink the latest log directory
[2026-01-07T10:37:59.977+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T10:38:07.806+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:38:08.084+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T10:38:08.125+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:38:09.303+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:38:10.244+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:38:13.786+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T10:38:14.455+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:32:07.281049+00:00 [running]> on host Halim-NVG.localdomain
[2026-01-07T10:38:16.853+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_staging', 'manual__2026-01-07T08:32:11.141448+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:39:03.114+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T10:39:10.348+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:39:10.422+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T10:39:10.431+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:39:10.949+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:39:11.073+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:39:12.009+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T10:39:12.350+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:32:11.141448+00:00 [queued]> on host Halim-NVG.localdomain
[2026-01-07T10:40:41.114+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_staging', run_id='manual__2026-01-07T08:32:07.281049+00:00', try_number=2, map_index=-1)
[2026-01-07T10:40:41.122+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_staging', run_id='manual__2026-01-07T08:32:11.141448+00:00', try_number=3, map_index=-1)
[2026-01-07T10:40:41.315+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=dbt_staging, run_id=manual__2026-01-07T08:32:07.281049+00:00, map_index=-1, run_start_date=2026-01-07 08:37:59.473731+00:00, run_end_date=2026-01-07 08:40:21.536097+00:00, run_duration=142.062366, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=2, job_id=37, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2026-01-07 08:37:04.707012+00:00, queued_by_job_id=31, pid=11729
[2026-01-07T10:40:41.326+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=dbt_staging, run_id=manual__2026-01-07T08:32:11.141448+00:00, map_index=-1, run_start_date=2026-01-07 08:39:12.751926+00:00, run_end_date=2026-01-07 08:40:40.251020+00:00, run_duration=87.499094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=3, max_tries=2, job_id=42, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2026-01-07 08:37:04.707012+00:00, queued_by_job_id=31, pid=11780
[2026-01-07T10:40:41.351+0200] {manager.py:293} ERROR - DagFileProcessorManager (PID=11681) last sent a heartbeat 213.52 seconds ago! Restarting it
[2026-01-07T10:40:41.369+0200] {process_utils.py:132} INFO - Sending 15 to group 11681. PIDs of all processes in the group: [11681]
[2026-01-07T10:40:41.376+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 11681
[2026-01-07T10:41:31.373+0200] {process_utils.py:80} INFO - Process psutil.Process(pid=11681, status='terminated', exitcode=0) (11681) terminated with exit code 0
[2026-01-07T10:41:31.395+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 11832
[2026-01-07T10:41:31.477+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T10:41:31.692+0200] {job.py:229} INFO - Heartbeat recovered after 277.63 seconds
[2026-01-07T10:41:31.954+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T10:41:32.009+0200] {scheduler_job_runner.py:1870} INFO - Marked 2 SchedulerJob instances as failed
[2026-01-07T10:41:32.046+0200] {scheduler_job_runner.py:1910} INFO - Reset the following 1 orphaned TaskInstances:
	<TaskInstance: metro_retail_pipeline.dbt_silver manual__2026-01-07T08:32:07.281049+00:00 [queued]>
[2026-01-07T10:41:32.611+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T10:41:37.850+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: metro_retail_pipeline.dbt_silver manual__2026-01-07T08:32:11.141448+00:00 [scheduled]>
[2026-01-07T10:41:37.852+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 1/16 running and queued tasks
[2026-01-07T10:41:37.855+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: metro_retail_pipeline.dbt_silver manual__2026-01-07T08:32:11.141448+00:00 [scheduled]>
[2026-01-07T10:41:37.893+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: metro_retail_pipeline.dbt_silver manual__2026-01-07T08:32:11.141448+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-01-07T10:41:37.898+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_silver', run_id='manual__2026-01-07T08:32:11.141448+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2026-01-07T10:41:37.901+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_silver', 'manual__2026-01-07T08:32:11.141448+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:41:37.940+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_silver', 'manual__2026-01-07T08:32:11.141448+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:43:03.933+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T10:43:23.636+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:43:23.808+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T10:43:23.824+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:43:24.715+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:43:25.088+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:43:26.794+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T10:43:27.401+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.dbt_silver manual__2026-01-07T08:32:11.141448+00:00 [queued]> on host Halim-NVG.localdomain
[2026-01-07T10:44:57.897+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_silver', run_id='manual__2026-01-07T08:32:11.141448+00:00', try_number=1, map_index=-1)
[2026-01-07T10:44:58.203+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=dbt_silver, run_id=manual__2026-01-07T08:32:11.141448+00:00, map_index=-1, run_start_date=2026-01-07 08:43:27.827415+00:00, run_end_date=2026-01-07 08:44:55.718897+00:00, run_duration=87.891482, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=2, job_id=45, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2026-01-07 08:44:53.312543+00:00, queued_by_job_id=23, pid=11887
[2026-01-07T10:44:58.239+0200] {manager.py:293} ERROR - DagFileProcessorManager (PID=11832) last sent a heartbeat 197.36 seconds ago! Restarting it
[2026-01-07T10:44:58.261+0200] {process_utils.py:132} INFO - Sending 15 to group 11832. PIDs of all processes in the group: [11832]
[2026-01-07T10:44:58.269+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 11832
[2026-01-07T10:45:59.509+0200] {process_utils.py:150} WARNING - process psutil.Process(pid=11832, name='airflow scheduler -- DagFileProcessorManager', status='disk-sleep') did not respond to SIGTERM. Trying SIGKILL
[2026-01-07T10:45:59.540+0200] {process_utils.py:87} INFO - Sending the signal 9 to group 11832
[2026-01-07T10:45:59.570+0200] {process_utils.py:80} INFO - Process psutil.Process(pid=11832, name='airflow scheduler -- DagFileProcessorManager', status='terminated', exitcode=<Negsignal.SIGKILL: -9>) (11832) terminated with exit code -9
[2026-01-07T10:45:59.589+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 11931
[2026-01-07T10:45:59.658+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T10:45:59.773+0200] {job.py:229} INFO - Heartbeat recovered after 268.22 seconds
[2026-01-07T10:46:00.882+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T10:46:39.637+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T10:46:39.694+0200] {scheduler_job_runner.py:1870} INFO - Marked 2 SchedulerJob instances as failed
[2026-01-07T10:46:39.708+0200] {scheduler_job_runner.py:1910} INFO - Reset the following 1 orphaned TaskInstances:
	<TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:32:07.281049+00:00 [queued]>
[2026-01-07T10:48:32.940+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T10:49:13.238+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T10:49:57.395+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>
[2026-01-07T10:49:57.401+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 0/16 running and queued tasks
[2026-01-07T10:49:57.405+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>
[2026-01-07T10:49:57.534+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:32:07.281049+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-01-07T10:49:57.542+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_gold', run_id='manual__2026-01-07T08:32:07.281049+00:00', try_number=3, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2026-01-07T10:49:57.546+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_gold', 'manual__2026-01-07T08:32:07.281049+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:49:57.704+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_gold', 'manual__2026-01-07T08:32:07.281049+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:51:00.109+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T10:51:09.021+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:51:09.410+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T10:51:09.430+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:51:11.122+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:51:11.447+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:51:13.842+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T10:51:14.382+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:32:07.281049+00:00 [failed]> on host Halim-NVG.localdomain
[2026-01-07T10:51:15.750+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_gold', run_id='manual__2026-01-07T08:32:07.281049+00:00', try_number=3, map_index=-1)
[2026-01-07T10:51:15.794+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=dbt_gold, run_id=manual__2026-01-07T08:32:07.281049+00:00, map_index=-1, run_start_date=2026-01-07 08:46:51.488215+00:00, run_end_date=2026-01-07 08:50:00.301610+00:00, run_duration=188.813395, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=3, max_tries=2, job_id=48, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-01-07 08:49:57.411111+00:00, queued_by_job_id=31, pid=11986
[2026-01-07T10:51:15.813+0200] {manager.py:293} ERROR - DagFileProcessorManager (PID=11931) last sent a heartbeat 78.17 seconds ago! Restarting it
[2026-01-07T10:51:15.820+0200] {process_utils.py:132} INFO - Sending 15 to group 11931. PIDs of all processes in the group: [11931]
[2026-01-07T10:51:15.823+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 11931
[2026-01-07T10:51:55.427+0200] {process_utils.py:80} INFO - Process psutil.Process(pid=11931, status='terminated', exitcode=0) (11931) terminated with exit code 0
[2026-01-07T10:51:55.444+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 12266
[2026-01-07T10:51:55.502+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T10:51:55.536+0200] {job.py:229} INFO - Heartbeat recovered after 125.26 seconds
[2026-01-07T10:51:55.696+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T10:51:56.023+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T10:52:23.471+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T10:52:27.208+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T10:52:35.999+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: metro_retail_pipeline.pull_weather_data manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>
[2026-01-07T10:52:36.016+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 0/16 running and queued tasks
[2026-01-07T10:52:36.021+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: metro_retail_pipeline.pull_weather_data manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>
[2026-01-07T10:52:36.051+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: metro_retail_pipeline.pull_weather_data manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-01-07T10:52:36.058+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='pull_weather_data', run_id='manual__2026-01-07T08:52:31.048330+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
[2026-01-07T10:52:36.062+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'pull_weather_data', 'manual__2026-01-07T08:52:31.048330+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:52:36.099+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'pull_weather_data', 'manual__2026-01-07T08:52:31.048330+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:54:00.928+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T10:54:18.661+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:54:18.767+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T10:54:18.777+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:54:21.414+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:54:21.701+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:54:26.168+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T10:54:26.861+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.pull_weather_data manual__2026-01-07T08:52:31.048330+00:00 [queued]> on host Halim-NVG.localdomain
[2026-01-07T10:55:15.878+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='pull_weather_data', run_id='manual__2026-01-07T08:52:31.048330+00:00', try_number=1, map_index=-1)
[2026-01-07T10:55:17.368+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=pull_weather_data, run_id=manual__2026-01-07T08:52:31.048330+00:00, map_index=-1, run_start_date=2026-01-07 08:54:28.025638+00:00, run_end_date=2026-01-07 08:55:10.657367+00:00, run_duration=42.631729, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=2, job_id=52, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2026-01-07 08:55:02.101058+00:00, queued_by_job_id=23, pid=12486
[2026-01-07T10:55:17.453+0200] {manager.py:293} ERROR - DagFileProcessorManager (PID=12266) last sent a heartbeat 159.01 seconds ago! Restarting it
[2026-01-07T10:55:17.492+0200] {process_utils.py:132} INFO - Sending 15 to group 12266. PIDs of all processes in the group: [12266]
[2026-01-07T10:55:17.497+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 12266
[2026-01-07T10:56:14.012+0200] {process_utils.py:80} INFO - Process psutil.Process(pid=12266, status='terminated', exitcode=0) (12266) terminated with exit code 0
[2026-01-07T10:56:14.056+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 12566
[2026-01-07T10:56:14.372+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T10:56:14.896+0200] {job.py:229} INFO - Heartbeat recovered after 228.04 seconds
[2026-01-07T10:56:15.973+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T10:57:01.951+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T10:57:01.998+0200] {scheduler_job_runner.py:1870} INFO - Marked 1 SchedulerJob instances as failed
[2026-01-07T10:57:02.010+0200] {scheduler_job_runner.py:1910} INFO - Reset the following 1 orphaned TaskInstances:
	<TaskInstance: metro_retail_pipeline.ingest_csv_files manual__2026-01-07T08:52:31.048330+00:00 [queued]>
[2026-01-07T10:57:21.163+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>
[2026-01-07T10:57:21.167+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 0/16 running and queued tasks
[2026-01-07T10:57:21.171+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>
[2026-01-07T10:57:21.198+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-01-07T10:57:21.207+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_staging', run_id='manual__2026-01-07T08:52:31.048330+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2026-01-07T10:57:21.213+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_staging', 'manual__2026-01-07T08:52:31.048330+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:57:21.239+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_staging', 'manual__2026-01-07T08:52:31.048330+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T10:58:58.690+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T10:59:21.512+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:59:21.640+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T10:59:21.657+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T10:59:23.252+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:59:24.857+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T10:59:30.564+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T10:59:32.474+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.dbt_staging manual__2026-01-07T08:52:31.048330+00:00 [queued]> on host Halim-NVG.localdomain
[2026-01-07T10:59:43.961+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_staging', run_id='manual__2026-01-07T08:52:31.048330+00:00', try_number=1, map_index=-1)
[2026-01-07T10:59:44.083+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=dbt_staging, run_id=manual__2026-01-07T08:52:31.048330+00:00, map_index=-1, run_start_date=2026-01-07 08:59:34.282018+00:00, run_end_date=2026-01-07 08:59:39.930384+00:00, run_duration=5.648366, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=2, job_id=56, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2026-01-07 08:57:21.175046+00:00, queued_by_job_id=31, pid=12719
[2026-01-07T10:59:44.109+0200] {manager.py:293} ERROR - DagFileProcessorManager (PID=12566) last sent a heartbeat 140.78 seconds ago! Restarting it
[2026-01-07T10:59:44.119+0200] {process_utils.py:132} INFO - Sending 15 to group 12566. PIDs of all processes in the group: [12566]
[2026-01-07T10:59:44.122+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 12566
[2026-01-07T11:00:26.556+0200] {process_utils.py:80} INFO - Process psutil.Process(pid=12566, status='terminated', exitcode=0) (12566) terminated with exit code 0
[2026-01-07T11:00:26.613+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 12767
[2026-01-07T11:00:26.761+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T11:00:26.955+0200] {job.py:229} INFO - Heartbeat recovered after 188.80 seconds
[2026-01-07T11:00:27.833+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T11:01:07.265+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>
[2026-01-07T11:01:07.278+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 0/16 running and queued tasks
[2026-01-07T11:01:07.283+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>
[2026-01-07T11:01:07.318+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-01-07T11:01:07.327+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_gold', run_id='manual__2026-01-07T08:52:31.048330+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2026-01-07T11:01:07.330+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_gold', 'manual__2026-01-07T08:52:31.048330+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T11:01:07.380+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'dbt_gold', 'manual__2026-01-07T08:52:31.048330+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T11:02:22.161+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T11:02:34.124+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T11:02:34.225+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T11:02:34.234+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T11:02:34.987+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T11:02:35.248+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T11:02:37.271+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T11:02:37.693+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.dbt_gold manual__2026-01-07T08:52:31.048330+00:00 [queued]> on host Halim-NVG.localdomain
[2026-01-07T11:02:40.735+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='dbt_gold', run_id='manual__2026-01-07T08:52:31.048330+00:00', try_number=1, map_index=-1)
[2026-01-07T11:02:41.123+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=dbt_gold, run_id=manual__2026-01-07T08:52:31.048330+00:00, map_index=-1, run_start_date=2026-01-07 09:02:38.018479+00:00, run_end_date=2026-01-07 09:02:39.171161+00:00, run_duration=1.152682, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=2, job_id=59, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-01-07 09:02:30.848159+00:00, queued_by_job_id=23, pid=12908
[2026-01-07T11:02:41.172+0200] {manager.py:293} ERROR - DagFileProcessorManager (PID=12767) last sent a heartbeat 92.40 seconds ago! Restarting it
[2026-01-07T11:02:41.187+0200] {process_utils.py:132} INFO - Sending 15 to group 12767. PIDs of all processes in the group: [12767]
[2026-01-07T11:02:41.190+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 12767
[2026-01-07T11:03:14.538+0200] {process_utils.py:80} INFO - Process psutil.Process(pid=12767, status='terminated', exitcode=0) (12767) terminated with exit code 0
[2026-01-07T11:03:14.603+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 12940
[2026-01-07T11:03:14.739+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T11:03:14.856+0200] {job.py:229} INFO - Heartbeat recovered after 133.93 seconds
[2026-01-07T11:03:15.298+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:03:15.379+0200] {scheduler_job_runner.py:1870} INFO - Marked 2 SchedulerJob instances as failed
[2026-01-07T11:03:15.416+0200] {scheduler_job_runner.py:1910} INFO - Reset the following 1 orphaned TaskInstances:
	<TaskInstance: metro_retail_pipeline.data_quality_checks manual__2026-01-07T08:52:31.048330+00:00 [queued]>
[2026-01-07T11:03:15.930+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T11:03:22.043+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: metro_retail_pipeline.data_quality_checks manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>
[2026-01-07T11:03:22.052+0200] {scheduler_job_runner.py:495} INFO - DAG metro_retail_pipeline has 0/16 running and queued tasks
[2026-01-07T11:03:22.060+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: metro_retail_pipeline.data_quality_checks manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>
[2026-01-07T11:03:22.120+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: metro_retail_pipeline.data_quality_checks manual__2026-01-07T08:52:31.048330+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-01-07T11:03:22.127+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='data_quality_checks', run_id='manual__2026-01-07T08:52:31.048330+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-01-07T11:03:22.132+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'data_quality_checks', 'manual__2026-01-07T08:52:31.048330+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T11:03:22.175+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'metro_retail_pipeline', 'data_quality_checks', 'manual__2026-01-07T08:52:31.048330+00:00', '--local', '--subdir', 'DAGS_FOLDER/metro_retail_pipeline.py']
[2026-01-07T11:04:20.770+0200] {dagbag.py:588} INFO - Filling up the DagBag from /mnt/c/Work/Projects/MetroRetail/dags/metro_retail_pipeline.py
[2026-01-07T11:04:30.827+0200] {example_kubernetes_executor.py:39} WARNING - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T11:04:30.899+0200] {example_local_kubernetes_executor.py:40} WARNING - Could not import DAGs in example_local_kubernetes_executor.py
Traceback (most recent call last):
  File "/mnt/c/Work/Projects/MetroRetail/.venv/lib/python3.12/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[2026-01-07T11:04:30.906+0200] {example_local_kubernetes_executor.py:41} WARNING - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes]
[2026-01-07T11:04:31.518+0200] {example_python_decorator.py:80} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T11:04:31.747+0200] {example_python_operator.py:93} WARNING - The virtalenv_python example task requires virtualenv, please install it.
[2026-01-07T11:04:33.180+0200] {tutorial_taskflow_api_virtualenv.py:29} WARNING - The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.
[2026-01-07T11:04:33.578+0200] {task_command.py:467} INFO - Running <TaskInstance: metro_retail_pipeline.data_quality_checks manual__2026-01-07T08:52:31.048330+00:00 [success]> on host Halim-NVG.localdomain
[2026-01-07T11:04:34.628+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='metro_retail_pipeline', task_id='data_quality_checks', run_id='manual__2026-01-07T08:52:31.048330+00:00', try_number=2, map_index=-1)
[2026-01-07T11:04:34.737+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=metro_retail_pipeline, task_id=data_quality_checks, run_id=manual__2026-01-07T08:52:31.048330+00:00, map_index=-1, run_start_date=2026-01-07 09:03:53.544909+00:00, run_end_date=2026-01-07 09:03:54.555762+00:00, run_duration=1.010853, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=2, job_id=62, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-01-07 09:03:22.067643+00:00, queued_by_job_id=31, pid=12957
[2026-01-07T11:04:34.767+0200] {manager.py:293} ERROR - DagFileProcessorManager (PID=12940) last sent a heartbeat 71.80 seconds ago! Restarting it
[2026-01-07T11:04:34.775+0200] {process_utils.py:132} INFO - Sending 15 to group 12940. PIDs of all processes in the group: [12940]
[2026-01-07T11:04:34.779+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 12940
[2026-01-07T11:05:03.708+0200] {process_utils.py:80} INFO - Process psutil.Process(pid=12940, status='terminated', exitcode=0) (12940) terminated with exit code 0
[2026-01-07T11:05:03.718+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 13052
[2026-01-07T11:05:03.754+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T11:05:03.811+0200] {job.py:229} INFO - Heartbeat recovered after 109.02 seconds
[2026-01-07T11:05:04.467+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T11:06:17.535+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:06:24.161+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:07:18.571+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:07:20.280+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:08:21.480+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:08:23.174+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:08:32.534+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:08:54.399+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:09:23.344+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:10:14.320+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:10:42.242+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:11:09.271+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:11:21.133+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:11:30.075+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:11:33.336+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:11:34.004+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:12:04.597+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:12:53.187+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:13:29.723+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:14:57.277+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:16:21.731+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:17:00.155+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:17:54.940+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:18:36.768+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:19:16.396+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:19:49.307+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:20:21.286+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:20:30.372+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:20:53.742+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:23:43.966+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:24:02.946+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:24:59.807+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:25:44.100+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:26:24.026+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:27:11.888+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:27:21.801+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:27:49.972+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:28:50.781+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:31:48.904+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:33:07.353+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:33:58.953+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:34:47.859+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:36:34.550+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:36:42.224+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:39:06.743+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:39:14.486+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:40:29.359+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:40:47.340+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:05.901+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:56.090+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:42:28.163+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:43:32.089+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:44:01.310+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:44:13.239+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:44:43.718+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:45:48.824+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:47:06.291+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:47:13.793+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:47:29.896+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:48:49.536+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:49:01.840+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:49:09.233+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:49:21.066+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:50:19.792+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:51:04.267+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:51:31.405+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:51:37.396+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:51:48.330+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:54:05.875+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:54:27.969+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:57:12.477+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:58:34.251+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:58:53.807+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:58:55.325+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:59:35.237+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:00:01.731+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:00:40.076+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:00:41.982+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:00:45.019+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:01:21.974+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:02:46.810+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:03:54.477+0200] {job.py:229} INFO - Heartbeat recovered after 32.32 seconds
[2026-01-07T12:04:43.015+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:05:54.792+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:06:41.773+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:07:03.129+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:07:38.104+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:08:02.690+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:08:16.680+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:09:22.156+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:09:50.148+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:10:02.786+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:23.795+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:32.301+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:11:38.456+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:11:55.313+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:12:58.266+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:13:07.808+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:13:39.926+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:14:40.525+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:14:57.032+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:16:05.692+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:17:48.538+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:18:39.506+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:18:44.855+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:19:56.345+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:20:04.901+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:20:06.178+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:20:11.216+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:20:12.980+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:21:05.427+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:21:09.507+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:21:17.322+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:22:21.791+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:22:39.152+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:22:50.722+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:23:34.172+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:23:38.215+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:23:45.511+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:24:12.740+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:24:14.773+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:24:37.136+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:25:12.549+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:27:21.199+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:29:57.057+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:30:27.049+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:32:16.568+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:33:26.353+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:35:24.544+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:35:35.890+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:39:21.550+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:39:51.816+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:40:06.056+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:40:43.700+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:42:33.056+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:43:06.070+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:43:40.558+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:44:51.176+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:45:22.202+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:45:51.083+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:46:44.229+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:46:57.326+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:46:59.158+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
 with pid: 12984
[2026-01-07T11:04:19.333+0200] {settings.py:63} INFO - Configured default timezone UTC
[2026-01-07T11:04:19.392+0200] {job.py:229} INFO - Heartbeat recovered after 111.30 seconds
[2026-01-07T11:04:20.125+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-01-07T11:07:04.919+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:07:07.731+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:08:24.585+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:09:05.469+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:10:28.466+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:10:49.961+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:12:11.431+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:12:42.216+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:15:02.986+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:15:15.212+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:16:49.141+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:17:18.180+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:18:41.774+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:19:03.834+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:20:00.716+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:20:19.271+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:20:56.101+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:21:00.904+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:21:13.424+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:21:36.511+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:22:25.483+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:23:27.860+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:24:04.839+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:24:15.517+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:26:31.621+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:26:54.801+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:27:31.647+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:27:32.121+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:29:01.439+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:31:53.640+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:32:39.556+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:33:03.901+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:36:02.839+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:36:40.138+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:37:29.319+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:37:47.264+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:38:47.142+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:38:54.296+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:38:56.064+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:40:05.227+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:18.578+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:42:08.090+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:42:12.229+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:42:13.893+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:42:31.764+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:42:54.770+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:43:15.333+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:43:30.197+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:45:05.996+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:45:28.954+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:45:42.153+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:46:30.039+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:47:07.441+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:48:02.313+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:48:47.674+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:48:51.468+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:49:49.859+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:50:19.785+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:50:28.183+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:50:36.389+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:52:04.978+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:52:26.595+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:53:07.764+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:53:09.956+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:53:42.853+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:53:59.902+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:54:37.154+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:54:38.735+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:55:29.839+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:55:41.481+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:56:01.145+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:57:28.786+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:58:17.270+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:00:46.634+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:01:29.718+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:02:28.400+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:03:11.227+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:03:29.993+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:07:32.088+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:08:04.778+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:08:22.768+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:08:38.062+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:08:40.927+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:19.704+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:21.481+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:22.530+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:58.181+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:12:21.250+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:12:27.532+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:13:02.243+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:13:44.735+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:14:19.024+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:14:32.312+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:15:14.050+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:15:59.555+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:16:01.733+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:18:52.148+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:19:37.756+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:19:54.558+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:20:15.539+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:21:17.322+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:23:29.967+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:23:59.807+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:24:03.502+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:24:09.910+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:24:27.090+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:25:33.730+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:26:56.053+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:27:58.200+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:28:13.791+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:29:06.467+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:29:08.700+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:30:01.463+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:31:03.984+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:31:07.620+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:34:11.193+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:34:15.630+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:35:12.942+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:35:18.372+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:35:58.912+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:38:14.754+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:38:24.458+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:39:22.973+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:39:34.067+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:40:31.036+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:40:47.795+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:41:47.586+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:41:56.603+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:42:22.138+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:42:34.809+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:43:05.654+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:43:47.694+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:44:07.628+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:44:30.532+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:44:47.602+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:45:02.831+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:46:30.849+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:47:21.278+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:47:48.946+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:47:50.763+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:49:05.696+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
 OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:02.696+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:07.184+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:13.875+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:41:16.606+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:39.437+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:49.624+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:41:53.702+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:42:01.393+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:42:55.787+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:44:45.227+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:45:36.713+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:45:38.589+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:46:21.339+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:48:39.128+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:49:05.593+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:49:07.370+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:50:34.418+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:50:51.576+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:51:28.876+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:51:39.177+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:54:29.987+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:55:24.232+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:56:10.103+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:56:12.008+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:56:35.725+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T11:56:45.075+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:56:57.554+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:58:41.648+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:58:50.054+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:59:21.598+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:01:17.977+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:01:43.020+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:02:34.542+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:05:11.028+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:06:50.670+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:07:04.680+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:07:35.839+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:07:56.500+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:09:20.218+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:09:29.231+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:32.619+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:11:34.946+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:11:47.365+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:11:58.274+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:12:10.274+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:13:58.889+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:15:36.037+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:17:06.352+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:19:53.980+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:20:35.962+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:20:39.964+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:20:57.698+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:21:13.555+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:21:19.464+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:21:21.339+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:21:45.047+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:22:14.183+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:26:27.139+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:27:22.463+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:32:29.329+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:32:34.673+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:32:36.731+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:33:24.465+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:33:52.541+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:35:45.102+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:35:51.159+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:36:31.386+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:36:52.274+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:37:37.021+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:38:03.708+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:38:19.662+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:38:22.599+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:39:16.101+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:40:21.064+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:41:28.262+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:42:00.654+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:42:47.087+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:43:34.785+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:44:06.529+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:44:42.926+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:45:45.516+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:45:49.460+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:46:56.027+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:47:45.636+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:47:55.038+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T11:58:29.957+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:58:39.776+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T11:58:51.608+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:00:29.010+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:02:08.593+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:02:26.374+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:04:01.986+0200] {job.py:229} INFO - Heartbeat recovered after 30.36 seconds
[2026-01-07T12:04:03.788+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:04:41.333+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:06:59.534+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:07:13.470+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:08:37.167+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:08:40.251+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:09:11.426+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:09:18.093+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:09:34.283+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:12.980+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:10:15.708+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:11:40.484+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:13:09.686+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:13:13.128+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:14:18.830+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:14:53.963+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:15:08.053+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:15:42.983+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:16:17.943+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:19:30.572+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:20:33.173+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:21:07.936+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:21:15.598+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:22:46.877+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:24:33.321+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:24:38.232+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:24:41.108+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:25:00.268+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:25:02.675+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:25:52.308+0200] {file_processor_handler.py:129} WARNING - C:\Work\Projects\MetroRetail\airflow_home/logs/scheduler/latest already exists as a dir/file. Skip creating symlink.
[2026-01-07T12:25:59.245+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:27:13.547+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:28:44.234+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:29:45.260+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:33:48.569+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:33:50.961+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:34:26.778+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:34:41.124+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:34:58.427+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:35:49.604+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:37:18.749+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:38:47.320+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:39:36.030+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:40:06.650+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:40:07.907+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:40:21.063+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:40:37.266+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:40:53.940+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:41:29.464+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:42:02.791+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:42:24.221+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:42:26.151+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:42:38.355+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:43:36.472+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:45:14.514+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-01-07T12:45:19.300+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:45:45.505+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:45:47.898+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:46:38.755+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
[2026-01-07T12:48:53.414+0200] {file_processor_handler.py:135} WARNING - OSError while attempting to symlink the latest log directory
